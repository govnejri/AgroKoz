"""
FastAPI сервер для YOLOv8 - Подсчет и классификация зерен пшеницы
Запуск: uvicorn server:app --host 0.0.0.0 --port 8000 --reload

════════════════════════════════════════════════════════════════════════════════
📐 ФОРМУЛА РАСЧЕТА ПОТЕРЬ ЗЕРНА
════════════════════════════════════════════════════════════════════════════════

Исходные данные:
    N     - количество обнаруженных зерен (шт)
    W1000 - вес 1000 зерен (г), обычно 35-45 г для пшеницы
    S     - площадь фотографируемого участка (м²)

Формула расчета потерь на гектар (кг/га):

    Потери (кг/га) = (N × W1000 / 1000) / S × 10000 / 1000

Пошаговый расчет:

    Шаг 1: Вес всех зерен на фото (г)
    ─────────────────────────────────────
    W_фото = (N × W1000) / 1000
    
    Пример: (25 зерен × 40 г) / 1000 = 1 г

    Шаг 2: Плотность потерь на 1 м² (г/м²)
    ───────────────────────────────────────
    Плотность = W_фото / S
    
    Пример: 1 г / 0.1 м² = 10 г/м²

    Шаг 3: Потери на гектар (кг/га)
    ────────────────────────────────
    Потери = (Плотность × 10000 м²) / 1000
    
    Пример: (10 г/м² × 10000) / 1000 = 100 кг/га

Упрощенная формула одной строкой:

    Потери = N × W1000 × 10 / S

    где: N - количество зерен
         W1000 - вес 1000 зерен в граммах
         S - площадь фото в м²
         Результат в кг/га

Классы зерен:
    • good (хорошее)     → учитывается в потерях
    • bad (поврежденное) → учитывается в потерях
    • impurity (примесь) → НЕ учитывается в потерях

Стандарты качества по ГОСТ:
    Отлично (A):         качество ≥ 95%
    Хорошо (B):          качество ≥ 80%
    Удовлетворительно (C): качество ≥ 60%
    Плохо (D):           качество < 60%

Примечания:
    - Типичная площадь рамки для отбора: 0.1 м² (рамка 31.6 × 31.6 см)
    - Вес 1000 зерен пшеницы: 30-50 г (зависит от сорта)
    - Допустимые потери при уборке: до 50 кг/га
    - Критические потери: > 100 кг/га

════════════════════════════════════════════════════════════════════════════════
"""

from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from ultralytics import YOLO
from PIL import Image, ImageDraw, ImageFont
import io
import numpy as np
from typing import Optional, Dict, List
import uvicorn
import cv2
from datetime import datetime
import base64

app = FastAPI(
    title="Wheat Grain Detection API",
    description="YOLOv8-based API для подсчета и классификации качества зерен пшеницы",
    version="1.0.0"
)

# CORS для мобильных приложений
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # В продакшене укажи конкретные домены
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Загружаем модель (можно выбрать любой формат)
MODEL_PATH = "/home/beka/Downloads/aghack/model/trained_models/best.pt"
# Альтернативно: для ONNX используй best.onnx
# MODEL_PATH = "/home/beka/Downloads/aghack/model/trained_models/best.onnx"

model = YOLO(MODEL_PATH)

# Классы согласно твоему датасету
CLASS_NAMES = {
    0: "good",        # Хорошее зерно
    1: "bad",         # Поврежденное/плохое зерно
    2: "impurity"     # Примесь/мусор
}

# Цвета для визуализации (RGB)
CLASS_COLORS = {
    0: (0, 255, 0),      # Зеленый для good
    1: (255, 0, 0),      # Красный для bad
    2: (255, 165, 0)     # Оранжевый для impurity
}


@app.on_event("startup")
async def startup_event():
    """Инициализация при запуске сервера"""
    print("=" * 70)
    print("🌾 WHEAT GRAIN QUALITY DETECTION API")
    print("=" * 70)
    print(f"📍 Model path: {MODEL_PATH}")
    print(f"🤖 Model type: YOLOv8-Nano")
    print(f"📊 Classes: {CLASS_NAMES}")
    
    # Warmup модели
    print("\n🔥 Warming up model...")
    dummy_img = np.zeros((640, 640, 3), dtype=np.uint8)
    model.predict(dummy_img, verbose=False)
    print("✅ Model loaded and warmed up successfully!")
    print("=" * 70)


@app.get("/")
async def root():
    """Базовая информация об API"""
    return {
        "service": "Wheat Grain Quality Detection API",
        "status": "online",
        "model": "YOLOv8-Nano",
        "classes": CLASS_NAMES,
        "version": "1.0.0",
        "endpoints": {
            "detect": "/detect",
            "detect_with_image": "/detect-with-image",
            "health": "/health",
            "docs": "/docs"
        }
    }


@app.get("/health")
async def health():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "model_loaded": model is not None
    }


@app.post("/detect")
async def detect_grains(
    file: UploadFile = File(..., description="Изображение зерен пшеницы"),
    confidence: float = Form(0.25, ge=0.0, le=1.0, description="Порог уверенности детекции"),
    iou: float = Form(0.45, ge=0.0, le=1.0, description="IoU порог для NMS")
):
    """
    Детекция и классификация зерен пшеницы
    
    Возвращает JSON с координатами, классами и статистикой
    """
    try:
        # Валидация типа файла
        if not file.content_type.startswith('image/'):
            raise HTTPException(
                status_code=400,
                detail="Файл должен быть изображением (JPEG, PNG)"
            )
        
        # Читаем изображение
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        # Конвертируем в RGB
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        img_width, img_height = image.size
        
        print(f"\n📸 Processing: {file.filename} ({img_width}x{img_height})")
        
        # Inference
        results = model.predict(
            source=image,
            conf=confidence,
            iou=iou,
            verbose=False,
            device='cpu'  # Используй 'cuda' если есть GPU
        )
        
        # Парсим результаты
        detections = []
        result = results[0]
        
        for idx, box in enumerate(result.boxes):
            # Координаты bbox
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            
            # Центр и размеры
            center_x = float((x1 + x2) / 2)
            center_y = float((y1 + y2) / 2)
            width = float(x2 - x1)
            height = float(y2 - y1)
            
            # Класс и уверенность
            class_id = int(box.cls[0].cpu().numpy())
            conf = float(box.conf[0].cpu().numpy())
            
            detection = {
                "id": idx,
                "class": CLASS_NAMES.get(class_id, f"unknown_{class_id}"),
                "class_id": class_id,
                "confidence": round(conf, 4),
                "bbox": {
                    "x1": round(float(x1), 2),
                    "y1": round(float(y1), 2),
                    "x2": round(float(x2), 2),
                    "y2": round(float(y2), 2),
                    "center_x": round(center_x, 2),
                    "center_y": round(center_y, 2),
                    "width": round(width, 2),
                    "height": round(height, 2)
                }
            }
            detections.append(detection)
        
        # Статистика по классам
        good_count = sum(1 for d in detections if d["class"] == "good")
        bad_count = sum(1 for d in detections if d["class"] == "bad")
        impurity_count = sum(1 for d in detections if d["class"] == "impurity")
        total_count = len(detections)
        
        # Процент качества
        quality_percentage = (good_count / total_count * 100) if total_count > 0 else 0
        
        statistics = {
            "total_grains": total_count,
            "good": good_count,
            "bad": bad_count,
            "impurity": impurity_count,
            "quality_percentage": round(quality_percentage, 2),
            "quality_grade": get_quality_grade(quality_percentage)
        }
        
        print(f"✅ Detection complete:")
        print(f"   Total: {total_count} | Good: {good_count} | Bad: {bad_count} | Impurity: {impurity_count}")
        print(f"   Quality: {quality_percentage:.1f}% ({statistics['quality_grade']})")
        
        return {
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "image_info": {
                "filename": file.filename,
                "width": img_width,
                "height": img_height
            },
            "detections": detections,
            "statistics": statistics,
            "parameters": {
                "confidence_threshold": confidence,
                "iou_threshold": iou
            }
        }
        
    except Exception as e:
        print(f"❌ Error during detection: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/detect-with-image")
async def detect_with_visualization(
    file: UploadFile = File(...),
    confidence: float = Form(0.25),
    iou: float = Form(0.45),
    return_image: bool = Form(True, description="Вернуть аннотированное изображение")
):
    """
    Детекция с возвратом аннотированного изображения
    
    Возвращает JSON + base64 encoded изображение с bbox'ами
    """
    try:
        # Читаем изображение
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        img_array = np.array(image)
        img_width, img_height = image.size
        
        # Inference
        results = model.predict(
            source=img_array,
            conf=confidence,
            iou=iou,
            verbose=False
        )
        
        result = results[0]
        
        # Парсим детекции
        detections = []
        for idx, box in enumerate(result.boxes):
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            class_id = int(box.cls[0].cpu().numpy())
            conf = float(box.conf[0].cpu().numpy())
            
            detections.append({
                "id": idx,
                "class": CLASS_NAMES[class_id],
                "class_id": class_id,
                "confidence": round(conf, 4),
                "bbox": {
                    "x1": round(float(x1), 2),
                    "y1": round(float(y1), 2),
                    "x2": round(float(x2), 2),
                    "y2": round(float(y2), 2)
                }
            })
        
        # Статистика
        good_count = sum(1 for d in detections if d["class"] == "good")
        bad_count = sum(1 for d in detections if d["class"] == "bad")
        impurity_count = sum(1 for d in detections if d["class"] == "impurity")
        total_count = len(detections)
        quality_percentage = (good_count / total_count * 100) if total_count > 0 else 0
        
        statistics = {
            "total_grains": total_count,
            "good": good_count,
            "bad": bad_count,
            "impurity": impurity_count,
            "quality_percentage": round(quality_percentage, 2),
            "quality_grade": get_quality_grade(quality_percentage)
        }
        
        # Визуализация
        annotated_image = None
        if return_image:
            annotated_array = draw_detections(img_array.copy(), result.boxes)
            annotated_image = Image.fromarray(annotated_array)
            
            # Конвертируем в base64
            buffered = io.BytesIO()
            annotated_image.save(buffered, format="JPEG", quality=90)
            img_base64 = base64.b64encode(buffered.getvalue()).decode()
        
        response = {
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "detections": detections,
            "statistics": statistics,
        }
        
        if return_image:
            response["annotated_image"] = f"data:image/jpeg;base64,{img_base64}"
        
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def draw_detections(image: np.ndarray, boxes) -> np.ndarray:
    """Рисует bbox'ы и лейблы на изображении"""
    img = image.copy()
    
    for box in boxes:
        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
        class_id = int(box.cls[0].cpu().numpy())
        conf = float(box.conf[0].cpu().numpy())
        
        # Цвет класса
        color = CLASS_COLORS.get(class_id, (255, 255, 255))
        
        # Рисуем bbox
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
        
        # Подготовка лейбла
        label = f"{CLASS_NAMES[class_id]} {conf:.2f}"
        
        # Размер текста
        (label_width, label_height), _ = cv2.getTextSize(
            label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
        )
        
        # Фон для текста
        cv2.rectangle(
            img,
            (x1, y1 - label_height - 10),
            (x1 + label_width, y1),
            color,
            -1
        )
        
        # Текст
        cv2.putText(
            img,
            label,
            (x1, y1 - 5),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (255, 255, 255),
            1,
            cv2.LINE_AA
        )
    
    return img


def get_quality_grade(percentage: float) -> str:
    """Определяет грейд качества зерна"""
    if percentage >= 95:
        return "Отлично (A)"
    elif percentage >= 85:
        return "Хорошо (B)"
    elif percentage >= 75:
        return "Удовлетворительно (C)"
    elif percentage >= 60:
        return "Плохо (D)"
    else:
        return "Очень плохо (F)"


@app.post("/batch-detect")
async def batch_detect(
    files: List[UploadFile] = File(...),
    confidence: float = Form(0.25)
):
    """
    Пакетная обработка нескольких изображений
    """
    results = []
    
    for file in files:
        try:
            contents = await file.read()
            image = Image.open(io.BytesIO(contents))
            
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Inference
            preds = model.predict(source=image, conf=confidence, verbose=False)
            
            # Статистика
            detections = preds[0].boxes
            good = sum(1 for box in detections if int(box.cls[0]) == 0)
            bad = sum(1 for box in detections if int(box.cls[0]) == 1)
            impurity = sum(1 for box in detections if int(box.cls[0]) == 2)
            total = len(detections)
            
            results.append({
                "filename": file.filename,
                "success": True,
                "statistics": {
                    "total": total,
                    "good": good,
                    "bad": bad,
                    "impurity": impurity,
                    "quality_percentage": round((good / total * 100) if total > 0 else 0, 2)
                }
            })
            
        except Exception as e:
            results.append({
                "filename": file.filename,
                "success": False,
                "error": str(e)
            })
    
    return {
        "success": True,
        "processed": len(files),
        "results": results
    }


if __name__ == "__main__":
    print("=" * 70)
    print("🌾 Starting Wheat Grain Detection API Server")
    print("=" * 70)
    print(f"📍 Model: {MODEL_PATH}")
    print(f"🌐 Server: http://0.0.0.0:8000")
    print(f"📖 API Docs: http://0.0.0.0:8000/docs")
    print(f"🔬 Interactive API: http://0.0.0.0:8000/redoc")
    print("=" * 70)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
        reload=True  # Auto-reload при изменении кода
    )
